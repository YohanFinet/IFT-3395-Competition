{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification d'articles ArXiv\n",
    "Équipe Yassine + JF + Yohan !\n",
    "Yassine Kassis : KASY20109609\n",
    "Yohan Finet : FINY05099600\n",
    "Jean-François G.Baril :  GIRJ08028200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table des matières\n",
    "* [Section 1 : Introduction] (#section1)\n",
    "* [Section 2 : Construction de traits caractéritiques](#section2)\n",
    "* [Section 3 : Algorithmes](#section3)\n",
    "* [Section 4 : Méthodologie](#section4)  \n",
    "* [Section 5 : Résultats](#section5)\n",
    "    * [Section 5.1 : Bayes Naïf] (#section5_1)\n",
    "    * [Section 5.2 : Autre] (#section5_2)\n",
    "* [Section 6 : Discussion](#section_6)\n",
    "* [Section 7 : Liste des contributions](#section_7)\n",
    "* [Section 8 : Références](#section_8)\n",
    "* [Section 9 : Appendice](#section_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Introduction<a class=\"anchor\"id=\"section1\"></a> \n",
    "Ce projet consiste a créer un classifieur de textes en implémentant un modèle de Bayes naïf et en utilisant d'autres modèles de notre choix. Les algorithmes on pour objectif de classer des documents texte parmi une liste de 15 sujets différents, soit les quinze catégories. Un des objectifs consiste à obtenir un taux de bonne classification qui est supérieur à certaines référence prédéfinies. L'entraînement a été fait sur un ensemble de 7500 documents classés par catégorie et les algorithmes ont été utilisé afin de classifier 15000 documents.\n",
    "\n",
    "Après avoir fait un prétraitement des données, notre approche a été de comparer les taux de bonnes classifications de différents algorithmes sur un ensemble de validation en faisant varier les hyperparamètres pour chacun d'eux. Nous avons ensuite choisi le modèle qui donnait le meilleur taux de bonnes classifications.\n",
    "\n",
    "Après avoir implémenté le classifieur de Bayes naïf et avoir dépassé toutes les références avec celui-ci, nous avons exploré différents algorithmes tels que la regression logistique, le SVM et la forêt aléatoire. Nous avons obtenu le meilleur taux de bonnes classifications avec le modèle de régression linéaire, soit un taux de 80,98%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 : Construction de traits caractéristiques<a class=\"anchor\"id=\"section2\"></a> \n",
    "Tout d'abord, pour chaque document de l'ensemble d'entraînement et de test nous avons enlevé les caractères spéciaux, les mots composés d'un seul caractère et les chiffres. Nous avons également remplacé les sauts de ligne par des espaces et les espaces multiples par des espaces simples. Nous avons ensuite enlevé les mots que nous avons jugé qu'ils n'aidaient pas à classifier les documents (voir no_word dans l'appendice). Finalement, pour chaque mot dans chaque document, nous avons regardé si ce mot contenait une lettre greque. Si c'était le cas, nous avons remplacé le mot par cette lettre greque. \n",
    "\n",
    "\\*\\*\\*traitement pour Bayes naïf*** Il faut savoir comment on calcule les occurance de chaque mot dans chacun des sujets afin d'avoir des proportions., etc\n",
    "\n",
    "Pour les algorithmes supplémentaires qui ont été essayées, nous avons utilisé WordNetLemmatizer du package nltk.stem afin de transformer les mots de chaque document dans leur forme de base. Nous avons ensuite utilisé TfidfVectorizer de la librairie scikit-learn afin de transformer les documents en vecteurs où chaque composante d'un vecteur représente la valeur tf-idf d'un mot. Chaque valeur tf-idf est proportionnelle à la fréquence d'un mot dans un document et inversement proportionnelle au nombre de documents qui contiennent ce mot. Nous avons calculé ces valeurs pour les mots uniques et pour les combinaisons de deux mots (ngram = 1.,)\n",
    "\n",
    "\n",
    "L'ensemble des documents de l'ensemble d'entraînement était alors séparé en un sous-ensemble d'entraînement et un sous-ensemble de validation.  Pour ce faire, nous avons aléatoirement choisi un 500 messages dans chacune des catégories afin de créer un jeu de données d'entraînement et nous avons réservés les 1000 (????) messages restants pour le jeu de test. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 :Algorithmes<a class=\"anchor\"id=\"section3\"></a> \n",
    "Nous avons tout d'abord utilisé un classifieur de Bayes naïf pour classifier les différents documents. Cet algorithme utilise le théorème de Bayes : P(c|d) = P(d|c)P(c)/P(d) ou c est une classe de document et d est un document. Le classifieur de Bayes naïf fait l'hypothèse que les mots d'un document sont indépendants sachant la classe. La classe prédite par le classifieur est donc donnée par la classe qui maximise le produit de P(c) avec le produit des P(w|c) pour chaque mot dans le document à classifier où P(c) est la proportion de documents de la classe c dans l'ensemble d'entraînement et P(w|c) est le nombre d'occurence du mot w divisé par le nombre de mot dans tout les document de la classe c dans l'ensemble d'entraînement.\n",
    "\n",
    "Nous avons également utilisé l'algorithme de regression logistique qui est essentiellement un réseau de neuronne avec un neuronne et dont la fonction d'activation est la fonction sigmoide. Une descente de gradient est utilisé afin de minimiser la fonction de coût choisie.\n",
    "\n",
    "L'algorithme du SVM a également été utilisé. Cet algorithme a pour but de trouver un hyperplan qui maximise la distance entre l'hyperplan et les points d'entraînement les plus près, c'est à dire l'hyperplan qui maximise la marge.\n",
    "\n",
    "Un algorithme de forêt aléatoire a aussi été utilisé afin de classifier les documents. Une forêt aléatoire entraîne plusieurs arbres de décision sur des sous-ensembles de l'ensemble d'entraînement et prédit une classe en moyennant les prédictions de tous les arbres. Chacun des arbres à plusieurs branche qui se divisent toutes en 2 jusqu'à arriver au feuilles. À chaque embranchement l'algorithme détermine quelle variable permet de prédire le mieux la classification d'un document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 : Méthodologie<a class=\"anchor\"id=\"section4\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5 : Résultats<a class=\"anchor\"id=\"section5\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5.1 : Classifieur de Bayes naïf<a class=\"anchor\"id=\"section5_1\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5.2 : Classifieur d'une autre façon<a class=\"anchor\"id=\"section5_2\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6 : Discussion<a class=\"anchor\"id=\"section6\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7 : Liste des contributions<a class=\"anchor\"id=\"section7\"></a> \n",
    "Bien que chacun des membres de cette équipe ait contribué en partie à toutes les étapes de ce projet, surtout dans la définition du problème et dans la discussion des solutions à développer.  Des efforts particuliers ont été déployés par les membres suivants dans les tâches indiquées:\n",
    "-Yassine Kassis, a travaillé particulièrement sur le développement de l'algorithme de classification de XXXXX\n",
    "-Yohan Finet a été particulièrement impliqué dans le développement du classifieur de Bayes naïf\n",
    "-Jean-François Baril a quand à lui travaillé sur la présentation des résultats et la rédaction du rapport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8 : Références<a class=\"anchor\"id=\"section8\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9 : Appendice<a class=\"anchor\"id=\"section9\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_word = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he'\n",
    "           , 'him', 'his', 'himself', 'she', 'her','hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs'\n",
    "           ,'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am','is', 'are', 'was', 'were'\n",
    "           , 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and'\n",
    "           , 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against'\n",
    "           , 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in'\n",
    "           , 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why'\n",
    "           , 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only',\n",
    "           'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm'\n",
    "           , 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', \n",
    "           'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
